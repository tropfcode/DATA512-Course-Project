{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a70e2464-92b7-4957-b1bb-e08b85ba9828",
   "metadata": {},
   "source": [
    "# Data pre-processing and preparation for analysis\n",
    "\n",
    "This notebook walks through the process and steps taken to prepare the full `USGS_Wildland_Fire_Combined_Dataset.json` dataset (full details of the dataset can be [found here](https://www.sciencebase.gov/catalog/item/61aa537dd34eb622f699df81)). There are steps that need to be taken for proper analysis such as extracting data from specific dates (specific months and years), projecting data into an appropriate coordinate system, etc.\n",
    "\n",
    "## Requirements\n",
    "1. `USGS_Wildland_Fire_Combined_Dataset.json` dataset file\n",
    "2. Custom python methods from `wildfire` directory placed at the same level as this notebook.\n",
    "\n",
    "## Citations\n",
    "This entire notebook is an adaptation of a code example developed by Dr. David W. McDonald for use in DATA 512, a course in the UW MS Data Science degree program. This code is provided under the [Creative Commons](https://creativecommons.org) [CC-BY license](https://creativecommons.org/licenses/by/4.0/). Revision 1.2 - August 16, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53930b48-8b6b-4233-a2d4-4a28e7b7b3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, os, json, time, re\n",
    "import geojson\n",
    "import geopandas as gpd\n",
    "from collections.abc import Iterable\n",
    "from geopy.distance import geodesic\n",
    "from pyproj import Transformer, Geod\n",
    "from shapely.geometry import Polygon, Point\n",
    "from shapely.ops import nearest_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd775ddf-eed4-4ea5-add8-43420e491887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looks like you're not using a 'PYTHONPATH' to specify the location of your python user modules.\n",
      "You may have to modify the sample code in this notebook to get the documented behaviors.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Set custom python modules in PYTHONPATH to import and use them.\n",
    "Set path to full dataset .json file.\n",
    "\"\"\"\n",
    "\n",
    "# Custom python modules\n",
    "MODULENAME = \"wildfire\"\n",
    "MODULEPATH = \"\"\n",
    "try:\n",
    "    ppath = os.environ.get('PYTHONPATH')\n",
    "    if not ppath: raise\n",
    "    MODULEPATH = os.path.join(ppath,MODULENAME)\n",
    "except:\n",
    "    # Likely here because a PYTHONPATH was not set, show a warning message\n",
    "    print(\"Looks like you're not using a 'PYTHONPATH' to specify the location of your python user modules.\")\n",
    "    print(\"You may have to modify the sample code in this notebook to get the documented behaviors.\")\n",
    "    MODULEPATH = \"\"\n",
    "\n",
    "DATA_FILENAME = \"./GeoJSON_Exports/USGS_Wildland_Fire_Combined_Dataset.json\"\n",
    "\n",
    "# Import custom python methods\n",
    "from wildfire.Reader import Reader as WFReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2662341a-1170-4ad2-b925-6cf503a95067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to open './GeoJSON_Exports/USGS_Wildland_Fire_Combined_Dataset.json' with wildfire.Reader() object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Attempting to open '{DATA_FILENAME}' with wildfire.Reader() object\")\n",
    "wfreader = WFReader(DATA_FILENAME)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd3c650a-a58c-481b-ac17-28e5314129f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1500 features\n",
      "Loaded 3000 features\n",
      "Loaded 4500 features\n",
      "Loaded 6000 features\n",
      "Loaded 7500 features\n",
      "Loaded 9000 features\n",
      "Loaded 10500 features\n",
      "Loaded 12000 features\n",
      "Loaded 13500 features\n",
      "Loaded 15000 features\n",
      "Loaded 16500 features\n",
      "Loaded 18000 features\n",
      "Loaded 19500 features\n",
      "Loaded 21000 features\n",
      "Loaded 22500 features\n",
      "Loaded 24000 features\n",
      "Loaded 25500 features\n",
      "Loaded 27000 features\n",
      "Loaded 28500 features\n",
      "Loaded 30000 features\n",
      "Loaded 31500 features\n",
      "Loaded 33000 features\n",
      "Loaded 34500 features\n",
      "Loaded 36000 features\n",
      "Loaded 37500 features\n",
      "Loaded 39000 features\n",
      "Loaded 40500 features\n",
      "Loaded 42000 features\n",
      "Loaded 43500 features\n",
      "Loaded 45000 features\n",
      "Loaded 46500 features\n",
      "Loaded 48000 features\n",
      "Loaded 49500 features\n",
      "Loaded 51000 features\n",
      "Loaded 52500 features\n",
      "Loaded 54000 features\n",
      "Loaded 55500 features\n",
      "Loaded 57000 features\n",
      "Loaded 58500 features\n",
      "Loaded 60000 features\n",
      "Loaded 61500 features\n",
      "Loaded 63000 features\n",
      "Loaded 64500 features\n",
      "Loaded 66000 features\n",
      "Loaded 67500 features\n",
      "Loaded 69000 features\n",
      "Loaded 70500 features\n",
      "Loaded 72000 features\n",
      "Loaded 73500 features\n",
      "Loaded 75000 features\n",
      "Loaded 76500 features\n",
      "Loaded 78000 features\n",
      "Loaded 79500 features\n",
      "Loaded 81000 features\n",
      "Loaded 82500 features\n",
      "Loaded 84000 features\n",
      "Loaded 85500 features\n",
      "Loaded 87000 features\n",
      "Loaded 88500 features\n",
      "Loaded 90000 features\n",
      "Loaded 91500 features\n",
      "Loaded 93000 features\n",
      "Loaded 94500 features\n",
      "Loaded 96000 features\n",
      "Loaded 97500 features\n",
      "Loaded 99000 features\n",
      "Loaded 100500 features\n",
      "Loaded 102000 features\n",
      "Loaded 103500 features\n",
      "Loaded 105000 features\n",
      "Loaded 106500 features\n",
      "Loaded 108000 features\n",
      "Loaded 109500 features\n",
      "Loaded 111000 features\n",
      "Loaded 112500 features\n",
      "Loaded 114000 features\n",
      "Loaded 115500 features\n",
      "Loaded 117000 features\n",
      "Loaded 118500 features\n",
      "Loaded 120000 features\n",
      "Loaded 121500 features\n",
      "Loaded 123000 features\n",
      "Loaded 124500 features\n",
      "Loaded 126000 features\n",
      "Loaded 127500 features\n",
      "Loaded 129000 features\n",
      "Loaded 130500 features\n",
      "Loaded 132000 features\n",
      "Loaded 133500 features\n",
      "Loaded 135000 features\n",
      "Loaded a total of 135061 features\n",
      "Variable 'feature_list' contains 135061 features\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load all features from dataset\n",
    "\"\"\"\n",
    "feature_list = []\n",
    "feature_count = 0\n",
    "\n",
    "wfreader.rewind()\n",
    "feature = wfreader.next()\n",
    "while feature:\n",
    "    feature_list.append(feature)\n",
    "    feature_count += 1\n",
    "    if (feature_count % 1500) == 0:\n",
    "        print(f\"Loaded {feature_count} features\")\n",
    "    feature = wfreader.next()\n",
    "\n",
    "print(f\"Loaded a total of {feature_count} features\")\n",
    "print(f\"Variable 'feature_list' contains {len(feature_list)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa8aff6-8c11-4d06-89da-698eca59098d",
   "metadata": {},
   "source": [
    "### Feature Discussion\n",
    "\n",
    "Some features are malformed -- that is, some of the rings represented by shapely Polygon or MultiPolygon objects do not exist in this dataset properly. So, we need to go through every feature, test if the Polygon is properly formed, and then turn it into an actual Polygon object.\n",
    "\n",
    "#### Assumptions\n",
    "It is assumed that the first ring for each feature represents the largest ring for that feature.\n",
    "See the comments in the code segement below for where that is happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83a820aa-df95-474c-8861-7c0f455c6f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 109604 has issues, determine what is wrong with data\n",
      "Feature 110223 has issues, determine what is wrong with data\n",
      "Feature 110638 has issues, determine what is wrong with data\n",
      "Feature 111430 has issues, determine what is wrong with data\n",
      "Feature 111896 has issues, determine what is wrong with data\n",
      "Feature 112409 has issues, determine what is wrong with data\n",
      "Feature 112414 has issues, determine what is wrong with data\n",
      "Feature 113410 has issues, determine what is wrong with data\n",
      "Feature 113664 has issues, determine what is wrong with data\n",
      "Feature 113737 has issues, determine what is wrong with data\n",
      "Feature 113765 has issues, determine what is wrong with data\n",
      "Feature 113804 has issues, determine what is wrong with data\n",
      "Feature 114308 has issues, determine what is wrong with data\n",
      "Feature 114321 has issues, determine what is wrong with data\n",
      "Feature 115628 has issues, determine what is wrong with data\n",
      "Feature 115973 has issues, determine what is wrong with data\n",
      "Feature 116234 has issues, determine what is wrong with data\n",
      "Feature 117085 has issues, determine what is wrong with data\n",
      "Feature 119581 has issues, determine what is wrong with data\n",
      "Feature 119616 has issues, determine what is wrong with data\n",
      "Feature 119750 has issues, determine what is wrong with data\n",
      "Feature 119981 has issues, determine what is wrong with data\n",
      "Feature 120211 has issues, determine what is wrong with data\n",
      "Feature 120677 has issues, determine what is wrong with data\n",
      "Feature 121009 has issues, determine what is wrong with data\n",
      "Feature 122263 has issues, determine what is wrong with data\n",
      "Feature 125744 has issues, determine what is wrong with data\n",
      "Feature 127491 has issues, determine what is wrong with data\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Remove bad features from dataset\n",
    "\"\"\"\n",
    "clean_features = []\n",
    "bad_features = []\n",
    "for i, wf_feature in enumerate(feature_list):\n",
    "    try:\n",
    "        if 'rings' in wf_feature['geometry']:\n",
    "            ring_data = wf_feature['geometry']['rings'][0] # Assuming first ring is largest\n",
    "        elif 'curveRings' in wf_feature['geometry']:\n",
    "            ring_data = wf_feature['geometry']['curveRings'][0] # Assuming first ring is largest\n",
    "        polygon = Polygon(ring_data)\n",
    "        clean_features.append(geojson.Feature(geometry=polygon, properties=wf_feature['attributes']))\n",
    "    except Exception as e:\n",
    "        print(f\"Feature {i} has issues, determine what is wrong with data\")\n",
    "        bad_features.append(wf_feature)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e1dfbd8-d655-420c-8714-e62d95c09118",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load cleaned up data into a geopandas Dataframe.\n",
    "\"\"\"\n",
    "# Full cleaned dataset in geopandas dataframe\n",
    "gdf = gpd.GeoDataFrame.from_features(clean_features)\n",
    "\n",
    "# Filtered dataframe containing features from the year 1961 to 2021\n",
    "# year_filtered_gdf = gdf[gdf['Fire_Year'] >= 1961]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f37b49e-e1b8-40eb-b7a6-084af69bb2ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSave complete cleaned dataset out in geojson format.\\nNOTE: The data has yet to be transformed to a different cooridinate system.\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Save complete cleaned dataset out in geojson format.\n",
    "NOTE: The data has yet to be transformed to a different cooridinate system.\n",
    "\"\"\"\n",
    "# full_geojson = 'full_data.geojson'\n",
    "# gdf.to_file(full_geojson, driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26622c4-3fd3-47c9-b03a-467a591c8310",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "Now that the data has been cleaned up, go to `visualization.ipynb` to use the cleaned data for creating visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee356c6d-eee0-4778-a087-81202fbcf0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
